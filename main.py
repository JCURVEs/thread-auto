"""
Thread-Auto: AI-powered Tech News Pipeline for Meta Threads.

This is the main entry point for the Thread-Auto pipeline.
It orchestrates RSS collection, AI analysis, and content formatting.

Usage:
    # Dry Run (default)
    python main.py

    # With environment variables
    OPENAI_API_KEY=sk-... DRY_RUN=True python main.py
"""

import os
from typing import Optional

from rss_collector import (
    fetch_feed,
    get_latest_entry,
    get_entry_info,
    DEFAULT_RSS_SOURCES
)
from image_extractor import get_article_image
from ai_analyzer import create_client, generate_thread_content, validate_content
from thread_formatter import print_dry_run, post_to_threads


# --- Configuration ---
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
THREADS_ACCESS_TOKEN = os.environ.get("THREADS_ACCESS_TOKEN")
RSS_URL = os.environ.get("RSS_URL", DEFAULT_RSS_SOURCES["techcrunch"])
DRY_RUN = os.environ.get("DRY_RUN", "True").lower() in ("true", "1", "yes")


def run_pipeline() -> None:
    """
    Execute the Thread-Auto pipeline.

    Pipeline steps:
    1. Fetch latest news from RSS feed
    2. Extract og:image from article
    3. Analyze content with GPT-4o
    4. Format and output (Dry Run or Production)
    """
    print("\n" + "#" * 50)
    print("# THREAD-AUTO PIPELINE")
    print("#" * 50)

    # Validate API key
    if not OPENAI_API_KEY:
        print("âŒ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   export OPENAI_API_KEY='sk-...'")
        return

    # Step 1: Fetch RSS feed
    print(f"\nðŸ”„ [Step 1] RSS í”¼ë“œ í™•ì¸ ì¤‘...")
    print(f"   URL: {RSS_URL}")

    feed = fetch_feed(RSS_URL)
    if not feed:
        print("âŒ RSS í”¼ë“œë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    entry = get_latest_entry(feed)
    if not entry:
        print("âŒ ìƒˆ ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    info = get_entry_info(entry)
    print(f"âœ… ìµœì‹  ê¸€ ë°œê²¬: {info['title']}")

    # Step 2: Extract image
    print(f"\nðŸ”„ [Step 2] ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘...")
    image_url = get_article_image(info["link"])
    if image_url:
        print(f"âœ… ì´ë¯¸ì§€ URL: {image_url[:60]}...")
    else:
        print("âš ï¸ ì´ë¯¸ì§€ ì—†ìŒ (í…ìŠ¤íŠ¸ë§Œ ê²Œì‹œ)")

    # Step 3: AI Analysis
    print(f"\nðŸ”„ [Step 3] AI ë¶„ì„ ì‹œìž‘...")
    client = create_client(OPENAI_API_KEY)
    content = generate_thread_content(
        client,
        info["title"],
        info["description"]
    )

    if not content or not validate_content(content):
        print("âŒ AI ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨")
        return

    print(f"âœ… ì½˜í…ì¸  ìƒì„± ì™„ë£Œ (íƒ€ìž…: {content['type']})")

    # Step 4: Output
    print(f"\nðŸ”„ [Step 4] ì¶œë ¥ ì²˜ë¦¬ ì¤‘...")
    if DRY_RUN:
        print("   ëª¨ë“œ: DRY RUN (í…ŒìŠ¤íŠ¸)")
        print_dry_run(content, image_url, info["link"])
    else:
        print("   ëª¨ë“œ: PRODUCTION")
        if THREADS_ACCESS_TOKEN:
            success = post_to_threads(
                content,
                image_url,
                info["link"],
                THREADS_ACCESS_TOKEN
            )
            if success:
                print("âœ… Threadsì— ê²Œì‹œ ì™„ë£Œ!")
            else:
                print("âŒ Threads ê²Œì‹œ ì‹¤íŒ¨")
        else:
            print("âŒ THREADS_ACCESS_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    print("\n" + "#" * 50)
    print("# PIPELINE ì™„ë£Œ")
    print("#" * 50 + "\n")


def example_rss_collector() -> None:
    """
    Demonstrate RSS collector functionality.
    """
    print("\n" + "=" * 50)
    print("RSS COLLECTOR ì˜ˆì œ")
    print("=" * 50)

    for name, url in list(DEFAULT_RSS_SOURCES.items())[:2]:
        print(f"\nðŸ“° {name.upper()}: {url}")
        feed = fetch_feed(url)
        if feed:
            entry = get_latest_entry(feed)
            if entry:
                info = get_entry_info(entry)
                print(f"   ì œëª©: {info['title'][:50]}...")
                print(f"   ë§í¬: {info['link'][:50]}...")


def example_image_extractor() -> None:
    """
    Demonstrate image extractor functionality.
    """
    print("\n" + "=" * 50)
    print("IMAGE EXTRACTOR ì˜ˆì œ")
    print("=" * 50)

    test_urls = [
        "https://techcrunch.com/",
        "https://www.theverge.com/",
    ]

    for url in test_urls:
        print(f"\nðŸ”— URL: {url}")
        image = get_article_image(url)
        if image:
            print(f"   ðŸ–¼ï¸ ì´ë¯¸ì§€: {image[:60]}...")
        else:
            print("   âš ï¸ ì´ë¯¸ì§€ ì—†ìŒ")


def main() -> None:
    """
    Main entry point for Thread-Auto application.
    """
    # Run the main pipeline
    run_pipeline()


if __name__ == "__main__":
    main()
